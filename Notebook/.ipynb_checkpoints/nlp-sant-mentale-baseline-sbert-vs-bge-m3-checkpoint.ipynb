{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "sourceId": 14207726,
     "sourceType": "datasetVersion",
     "datasetId": 9061705
    }
   ],
   "dockerImageVersionId": 31260,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# NLP Santé mentale – Baseline SBERT vs BGE‑M3\n\nNotebook prêt à exécuter sur Kaggle avec le dataset *Mental Health Text Classification Dataset (4‑Class)*.\n\n- Données : fichiers `mental_heath_unbanlanced.csv` (train) et `mental_health_combined_test.csv` (test)\n- Baseline : SBERT embeddings + régression logistique\n- Nouveau modèle : BGE‑M3 embeddings + régression logistique\n\nRemarque : le fichier `mental_heath_feature_engineered.csv` est optionnel et non utilisé ici.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "!pip -q install sentence-transformers --no-deps\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-01-28T13:43:47.182779Z",
     "iopub.execute_input": "2026-01-28T13:43:47.183142Z",
     "iopub.status.idle": "2026-01-28T13:43:49.544321Z",
     "shell.execute_reply.started": "2026-01-28T13:43:47.183109Z",
     "shell.execute_reply": "2026-01-28T13:43:49.543296Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "import numpy as np\nimport pandas as pd\nimport sklearn\nimport torch\nfrom sentence_transformers import SentenceTransformer\n\nprint(\"numpy\", np.__version__)\nprint(\"pandas\", pd.__version__)\nprint(\"sklearn\", sklearn.__version__)\nprint(\"torch\", torch.__version__)\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-01-28T13:43:49.546072Z",
     "iopub.execute_input": "2026-01-28T13:43:49.546337Z",
     "iopub.status.idle": "2026-01-28T13:43:49.552239Z",
     "shell.execute_reply.started": "2026-01-28T13:43:49.546308Z",
     "shell.execute_reply": "2026-01-28T13:43:49.551518Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output directory that works on Kaggle and locally\n",
    "import os\n",
    "\n",
    "OUTPUT_DIR = os.getenv('KAGGLE_WORKING_DIR', '/kaggle/working')\n",
    "if not os.path.isdir(OUTPUT_DIR):\n",
    "    OUTPUT_DIR = 'models'\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "print('OUTPUT_DIR =', OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "source": "import os\nimport numpy as np\nimport pandas as pd\n\nfrom sentence_transformers import SentenceTransformer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, confusion_matrix",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-01-28T13:43:49.553248Z",
     "iopub.execute_input": "2026-01-28T13:43:49.553454Z",
     "iopub.status.idle": "2026-01-28T13:43:49.67196Z",
     "shell.execute_reply.started": "2026-01-28T13:43:49.553433Z",
     "shell.execute_reply": "2026-01-28T13:43:49.671306Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# Chemins des fichiers du dataset Kaggle\n# Adapter uniquement si le dossier Kaggle diffère\nbase_dir = \"/kaggle/input/mental-health-text-classification-dataset\"\n\ntrain_path = os.path.join(base_dir, \"mental_heath_unbanlanced.csv\")\ntest_path = os.path.join(base_dir, \"mental_health_combined_test.csv\")\n\nprint(\"Fichiers disponibles dans le dossier dataset :\")\nprint(os.listdir(base_dir))",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-01-28T13:43:52.343464Z",
     "iopub.execute_input": "2026-01-28T13:43:52.345173Z",
     "iopub.status.idle": "2026-01-28T13:43:52.3657Z",
     "shell.execute_reply.started": "2026-01-28T13:43:52.345142Z",
     "shell.execute_reply": "2026-01-28T13:43:52.365066Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# Chargement des données\ndf_train = pd.read_csv(train_path).dropna(subset=[\"text\", \"status\"]).copy()\ndf_test = pd.read_csv(test_path).dropna(subset=[\"text\", \"status\"]).copy()\n\nprint(\"Train:\", df_train.shape)\nprint(\"Test :\", df_test.shape)\nprint(\"\\nColonnes train:\", list(df_train.columns))\nprint(\"\\nRépartition des classes (train):\")\nprint(df_train[\"status\"].value_counts())",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-01-28T13:43:52.794354Z",
     "iopub.execute_input": "2026-01-28T13:43:52.795304Z",
     "iopub.status.idle": "2026-01-28T13:43:53.31626Z",
     "shell.execute_reply.started": "2026-01-28T13:43:52.795266Z",
     "shell.execute_reply": "2026-01-28T13:43:53.315395Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# EDA minimal : longueurs de texte (caractères et mots)\ndf_train[\"text_len\"] = df_train[\"text\"].astype(str).str.len()\ndf_train[\"word_count\"] = df_train[\"text\"].astype(str).str.split().map(len)\n\ndf_train[[\"text_len\", \"word_count\"]].describe(percentiles=[0.5, 0.9, 0.95, 0.99])",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-01-28T13:43:53.328014Z",
     "iopub.execute_input": "2026-01-28T13:43:53.328534Z",
     "iopub.status.idle": "2026-01-28T13:43:53.898514Z",
     "shell.execute_reply.started": "2026-01-28T13:43:53.328506Z",
     "shell.execute_reply": "2026-01-28T13:43:53.897642Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# Encodage des labels\nlabel_encoder = LabelEncoder()\ny = label_encoder.fit_transform(df_train[\"status\"])\ny_test = label_encoder.transform(df_test[\"status\"])\n\nX = df_train[\"text\"].astype(str).tolist()\nX_test = df_test[\"text\"].astype(str).tolist()\n\nprint(\"Classes:\", list(label_encoder.classes_))",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-01-28T13:43:53.900063Z",
     "iopub.execute_input": "2026-01-28T13:43:53.900333Z",
     "iopub.status.idle": "2026-01-28T13:43:53.917983Z",
     "shell.execute_reply.started": "2026-01-28T13:43:53.900308Z",
     "shell.execute_reply": "2026-01-28T13:43:53.917243Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# Split train / validation\n# Le jeu de test reste séparé et n'est pas utilisé pendant l'entraînement\nX_tr, X_val, y_tr, y_val = train_test_split(\n    X, y, test_size=0.2, stratify=y, random_state=42\n)\n\nprint(\"Train split:\", len(X_tr))\nprint(\"Val split  :\", len(X_val))",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-01-28T13:43:53.919084Z",
     "iopub.execute_input": "2026-01-28T13:43:53.919383Z",
     "iopub.status.idle": "2026-01-28T13:43:53.967525Z",
     "shell.execute_reply.started": "2026-01-28T13:43:53.919359Z",
     "shell.execute_reply": "2026-01-28T13:43:53.966823Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# Cache d'embeddings sur disque pour éviter de recalculer en cas de relance\ndef embed_with_cache(model, texts, path, batch_size=32):\n    if os.path.exists(path):\n        return np.load(path)\n    emb = model.encode(\n        texts,\n        batch_size=batch_size,\n        show_progress_bar=True,\n        convert_to_numpy=True\n    )\n    np.save(path, emb)\n    return emb",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-01-28T13:43:54.324334Z",
     "iopub.execute_input": "2026-01-28T13:43:54.324667Z",
     "iopub.status.idle": "2026-01-28T13:43:54.329155Z",
     "shell.execute_reply.started": "2026-01-28T13:43:54.324629Z",
     "shell.execute_reply": "2026-01-28T13:43:54.328419Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# Entraînement + évaluation d'un classifieur simple\ndef train_and_eval(emb_tr, emb_val, emb_test, y_tr, y_val, y_test, class_names):\n    clf = LogisticRegression(max_iter=2000, n_jobs=-1, class_weight=\"balanced\")\n    clf.fit(emb_tr, y_tr)\n\n    val_pred = clf.predict(emb_val)\n    test_pred = clf.predict(emb_test)\n\n    val_report = classification_report(y_val, val_pred, target_names=class_names, output_dict=True)\n    test_report = classification_report(y_test, test_pred, target_names=class_names, output_dict=True)\n\n    return clf, val_pred, test_pred, val_report, test_report",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-01-28T13:43:54.496407Z",
     "iopub.execute_input": "2026-01-28T13:43:54.497029Z",
     "iopub.status.idle": "2026-01-28T13:43:54.501637Z",
     "shell.execute_reply.started": "2026-01-28T13:43:54.496999Z",
     "shell.execute_reply": "2026-01-28T13:43:54.500927Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## Baseline : SBERT embeddings + régression logistique",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Modèle SBERT baseline (embeddings généralistes solides)\nsbert_name = \"sentence-transformers/all-mpnet-base-v2\"\nsbert = SentenceTransformer(sbert_name)\n\n# Option utile si tu veux accélérer (et si tu acceptes une perte potentielle de qualité)\n# sbert.max_seq_length = 256\n\nX_tr_sbert = embed_with_cache(sbert, X_tr, \"/kaggle/working/X_tr_sbert.npy\", batch_size=64)\nX_val_sbert = embed_with_cache(sbert, X_val, \"/kaggle/working/X_val_sbert.npy\", batch_size=64)\nX_test_sbert = embed_with_cache(sbert, X_test, \"/kaggle/working/X_test_sbert.npy\", batch_size=64)\n\nclf_sbert, val_pred_sbert, test_pred_sbert, val_rep_sbert, test_rep_sbert = train_and_eval(\n    X_tr_sbert, X_val_sbert, X_test_sbert, y_tr, y_val, y_test, label_encoder.classes_\n)\n\nprint(\"SBERT - validation\")\nprint(classification_report(y_val, val_pred_sbert, target_names=label_encoder.classes_))\nprint(\"SBERT - test\")\nprint(classification_report(y_test, test_pred_sbert, target_names=label_encoder.classes_))",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-01-28T13:43:55.072402Z",
     "iopub.execute_input": "2026-01-28T13:43:55.072742Z",
     "iopub.status.idle": "2026-01-28T13:44:11.664864Z",
     "shell.execute_reply.started": "2026-01-28T13:43:55.072713Z",
     "shell.execute_reply": "2026-01-28T13:44:11.663601Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# Matrice de confusion SBERT sur le test\nfrom sklearn.metrics import confusion_matrix\n\nconfusion_matrix(y_test, test_pred_sbert)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-01-28T13:44:21.650812Z",
     "iopub.execute_input": "2026-01-28T13:44:21.651526Z",
     "iopub.status.idle": "2026-01-28T13:44:21.659457Z",
     "shell.execute_reply.started": "2026-01-28T13:44:21.651489Z",
     "shell.execute_reply": "2026-01-28T13:44:21.658763Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "import matplotlib.pyplot as plt\nfrom sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n\n# Calcul de la matrice de confusion pour SBERT\ncm_sbert = confusion_matrix(y_test, test_pred_sbert)\n\n# Affichage graphique\ndisp = ConfusionMatrixDisplay(\n    confusion_matrix=cm_sbert,\n    display_labels=label_encoder.classes_\n)\n\nplt.figure(figsize=(6, 6))\ndisp.plot(cmap=\"Blues\", values_format=\"d\")\nplt.title(\"Matrice de confusion – SBERT\")\nplt.grid(False)\nplt.show()\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-01-28T13:44:24.445588Z",
     "iopub.execute_input": "2026-01-28T13:44:24.445947Z",
     "iopub.status.idle": "2026-01-28T13:44:24.671157Z",
     "shell.execute_reply.started": "2026-01-28T13:44:24.445919Z",
     "shell.execute_reply": "2026-01-28T13:44:24.670331Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "from sklearn.metrics import accuracy_score, f1_score\n\ndef compute_metrics(y_true, y_pred):\n    return {\n        \"accuracy\": float(accuracy_score(y_true, y_pred)),\n        \"f1_macro\": float(f1_score(y_true, y_pred, average=\"macro\")),\n        \"f1_weighted\": float(f1_score(y_true, y_pred, average=\"weighted\")),\n    }\n\nRESULTS = []\n\ndef add_result(modele, embeddings, split, y_true, y_pred):\n    row = {\n        \"modele\": modele,\n        \"embeddings\": embeddings,\n        \"split\": split,\n        **compute_metrics(y_true, y_pred),\n    }\n    RESULTS.append(row)\n    return row\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-01-28T13:47:53.159518Z",
     "iopub.execute_input": "2026-01-28T13:47:53.160189Z",
     "iopub.status.idle": "2026-01-28T13:47:53.165287Z",
     "shell.execute_reply.started": "2026-01-28T13:47:53.160154Z",
     "shell.execute_reply": "2026-01-28T13:47:53.164642Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "from sklearn.metrics import accuracy_score, f1_score\n\nadd_result(\"LogisticRegression\", \"SBERT\", \"validation\", y_val, val_pred_sbert)\nadd_result(\"LogisticRegression\", \"SBERT\", \"test\", y_test, test_pred_sbert)\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-01-28T13:47:57.0722Z",
     "iopub.execute_input": "2026-01-28T13:47:57.072528Z",
     "iopub.status.idle": "2026-01-28T13:47:57.088564Z",
     "shell.execute_reply.started": "2026-01-28T13:47:57.0725Z",
     "shell.execute_reply": "2026-01-28T13:47:57.087932Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# Libérer la mémoire GPU entre SBERT et BGE\nimport gc, torch\n\ndel sbert, X_tr_sbert, X_val_sbert, X_test_sbert\ngc.collect()\ntorch.cuda.empty_cache()",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-01-28T13:48:00.913991Z",
     "iopub.execute_input": "2026-01-28T13:48:00.914671Z",
     "iopub.status.idle": "2026-01-28T13:48:01.426831Z",
     "shell.execute_reply.started": "2026-01-28T13:48:00.914606Z",
     "shell.execute_reply": "2026-01-28T13:48:01.426177Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## Nouveau modèle : BGE‑M3 embeddings + régression logistique",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Modèle BGE-M3 (embeddings récents)\nbge_name = \"BAAI/bge-m3\"\nbge = SentenceTransformer(bge_name)\nbge.max_seq_length = 128\n\n\n# Option utile si tu veux accélérer (réduit la longueur max traitée)\n# bge.max_seq_length = 256\n\nX_tr_bge = embed_with_cache(bge, X_tr, \"/kaggle/working/X_tr_bge.npy\", batch_size=8)\nX_val_bge = embed_with_cache(bge, X_val, \"/kaggle/working/X_val_bge.npy\", batch_size=8)\nX_test_bge = embed_with_cache(bge, X_test, \"/kaggle/working/X_test_bge.npy\", batch_size=8)\n\n\nclf_bge, val_pred_bge, test_pred_bge, val_rep_bge, test_rep_bge = train_and_eval(\n    X_tr_bge, X_val_bge, X_test_bge, y_tr, y_val, y_test, label_encoder.classes_\n)\n\nprint(\"BGE-M3 - validation\")\nprint(classification_report(y_val, val_pred_bge, target_names=label_encoder.classes_))\nprint(\"BGE-M3 - test\")\nprint(classification_report(y_test, test_pred_bge, target_names=label_encoder.classes_))",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-01-28T13:48:05.558086Z",
     "iopub.execute_input": "2026-01-28T13:48:05.558783Z",
     "iopub.status.idle": "2026-01-28T13:48:40.139147Z",
     "shell.execute_reply.started": "2026-01-28T13:48:05.558752Z",
     "shell.execute_reply": "2026-01-28T13:48:40.13855Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# Matrice de confusion BGE-M3 sur le test\nconfusion_matrix(y_test, test_pred_bge)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-01-28T13:48:54.829823Z",
     "iopub.execute_input": "2026-01-28T13:48:54.830162Z",
     "iopub.status.idle": "2026-01-28T13:48:54.837189Z",
     "shell.execute_reply.started": "2026-01-28T13:48:54.830125Z",
     "shell.execute_reply": "2026-01-28T13:48:54.836473Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# Calcul de la matrice de confusion pour BGE-M3\ncm_bge = confusion_matrix(y_test, test_pred_bge)\n\n# Affichage graphique\ndisp = ConfusionMatrixDisplay(\n    confusion_matrix=cm_bge,\n    display_labels=label_encoder.classes_\n)\n\nplt.figure(figsize=(6, 6))\ndisp.plot(cmap=\"Blues\", values_format=\"d\")\nplt.title(\"Matrice de confusion – BGE-M3\")\nplt.grid(False)\nplt.show()\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-01-28T13:48:56.317042Z",
     "iopub.execute_input": "2026-01-28T13:48:56.317392Z",
     "iopub.status.idle": "2026-01-28T13:48:56.492893Z",
     "shell.execute_reply.started": "2026-01-28T13:48:56.317353Z",
     "shell.execute_reply": "2026-01-28T13:48:56.492116Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## Comparaison synthétique",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Tableau de comparaison (macro F1 et accuracy)\ndef extract_metrics(rep):\n    return {\n        \"accuracy\": rep[\"accuracy\"],\n        \"f1_macro\": rep[\"macro avg\"][\"f1-score\"],\n        \"precision_macro\": rep[\"macro avg\"][\"precision\"],\n        \"recall_macro\": rep[\"macro avg\"][\"recall\"],\n    }\n\nrows = []\nrows.append({\"modele\": \"SBERT\", \"split\": \"validation\", **extract_metrics(val_rep_sbert)})\nrows.append({\"modele\": \"SBERT\", \"split\": \"test\", **extract_metrics(test_rep_sbert)})\nrows.append({\"modele\": \"BGE-M3\", \"split\": \"validation\", **extract_metrics(val_rep_bge)})\nrows.append({\"modele\": \"BGE-M3\", \"split\": \"test\", **extract_metrics(test_rep_bge)})\n\ndf_compare = pd.DataFrame(rows)\ndf_compare",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-01-28T13:49:03.916259Z",
     "iopub.execute_input": "2026-01-28T13:49:03.916812Z",
     "iopub.status.idle": "2026-01-28T13:49:03.929759Z",
     "shell.execute_reply.started": "2026-01-28T13:49:03.916781Z",
     "shell.execute_reply": "2026-01-28T13:49:03.928778Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# Sauvegarde des métriques\nout_path = \"/kaggle/working/metrics_compare.csv\"\ndf_compare.to_csv(out_path, index=False)\nout_path",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-01-28T13:49:07.326979Z",
     "iopub.execute_input": "2026-01-28T13:49:07.327547Z",
     "iopub.status.idle": "2026-01-28T13:49:07.339105Z",
     "shell.execute_reply.started": "2026-01-28T13:49:07.327518Z",
     "shell.execute_reply": "2026-01-28T13:49:07.338273Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## Notes\n\n- Le jeu `mental_health_combined_test.csv` est réservé à l’évaluation finale.\n- Le fichier `mental_heath_feature_engineered.csv` est utile pour des baselines classiques, mais pas nécessaire pour SBERT/BGE.\nlightgbm- Autres options si la RAM GPU est limitée, `batch_size` ou fixe `max_seq_length = 256`.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "!pip -q install -U lightgbm\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-01-28T13:49:17.287399Z",
     "iopub.execute_input": "2026-01-28T13:49:17.288013Z",
     "iopub.status.idle": "2026-01-28T13:49:20.657676Z",
     "shell.execute_reply.started": "2026-01-28T13:49:17.287983Z",
     "shell.execute_reply": "2026-01-28T13:49:20.656565Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "import os\nimport json\nimport numpy as np\nimport pandas as pd\n\nimport lightgbm as lgb\n\nfrom sklearn.svm import LinearSVC\nfrom sklearn.metrics import classification_report, accuracy_score, f1_score\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-01-28T13:49:23.14705Z",
     "iopub.execute_input": "2026-01-28T13:49:23.147808Z",
     "iopub.status.idle": "2026-01-28T13:49:26.982525Z",
     "shell.execute_reply.started": "2026-01-28T13:49:23.147768Z",
     "shell.execute_reply": "2026-01-28T13:49:26.981695Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "def run_lgbm_multiclass(X_tr_emb, y_tr, X_val_emb, y_val, X_test_emb, y_test, class_names, run_name, seed=42):\n    # LightGBM aime bien le float32\n    X_tr_emb = X_tr_emb.astype(np.float32)\n    X_val_emb = X_val_emb.astype(np.float32)\n    X_test_emb = X_test_emb.astype(np.float32)\n\n    train_set = lgb.Dataset(X_tr_emb, label=y_tr)\n    val_set = lgb.Dataset(X_val_emb, label=y_val, reference=train_set)\n\n    params = {\n        \"objective\": \"multiclass\",\n        \"num_class\": len(class_names),\n        \"metric\": \"multi_logloss\",\n        \"learning_rate\": 0.05,\n        \"num_leaves\": 63,\n        \"feature_fraction\": 0.9,\n        \"bagging_fraction\": 0.9,\n        \"bagging_freq\": 1,\n        \"min_data_in_leaf\": 30,\n        \"lambda_l2\": 1.0,\n        \"verbosity\": -1,\n        \"seed\": seed,\n    }\n\n    model = lgb.train(\n        params,\n        train_set,\n        num_boost_round=5000,\n        valid_sets=[val_set],\n        valid_names=[\"val\"],\n        callbacks=[\n            lgb.early_stopping(stopping_rounds=100),\n            lgb.log_evaluation(period=50),\n        ],\n    )\n\n    val_proba = model.predict(X_val_emb)\n    test_proba = model.predict(X_test_emb)\n\n    val_pred = np.argmax(val_proba, axis=1)\n    test_pred = np.argmax(test_proba, axis=1)\n\n    print(f\"{run_name} - validation\")\n    print(classification_report(y_val, val_pred, target_names=class_names))\n\n    print(f\"{run_name} - test\")\n    print(classification_report(y_test, test_pred, target_names=class_names))\n\n    add_result(\"LightGBM\", run_name, \"validation\", y_val, val_pred)\n    add_result(\"LightGBM\", run_name, \"test\", y_test, test_pred)\n\n    return model, val_pred, test_pred\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-01-28T13:49:31.48293Z",
     "iopub.execute_input": "2026-01-28T13:49:31.484232Z",
     "iopub.status.idle": "2026-01-28T13:49:31.491684Z",
     "shell.execute_reply.started": "2026-01-28T13:49:31.484197Z",
     "shell.execute_reply": "2026-01-28T13:49:31.490839Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# SBERT\nX_tr_sbert  = np.load(\"/kaggle/working/X_tr_sbert.npy\")\nX_val_sbert = np.load(\"/kaggle/working/X_val_sbert.npy\")\nX_test_sbert = np.load(\"/kaggle/working/X_test_sbert.npy\")\n\n# BGE-M3\nX_tr_bge  = np.load(\"/kaggle/working/X_tr_bge.npy\")\nX_val_bge = np.load(\"/kaggle/working/X_val_bge.npy\")\nX_test_bge = np.load(\"/kaggle/working/X_test_bge.npy\")\n\nprint(\"SBERT :\", X_tr_sbert.shape, X_val_sbert.shape, X_test_sbert.shape)\nprint(\"BGE-M3:\", X_tr_bge.shape, X_val_bge.shape, X_test_bge.shape)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-01-28T13:49:47.370913Z",
     "iopub.execute_input": "2026-01-28T13:49:47.371776Z",
     "iopub.status.idle": "2026-01-28T13:49:47.51496Z",
     "shell.execute_reply.started": "2026-01-28T13:49:47.371744Z",
     "shell.execute_reply": "2026-01-28T13:49:47.514325Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "model_lgb_sbert, val_pred_lgb_sbert, test_pred_lgb_sbert = run_lgbm_multiclass(\n    X_tr_sbert, y_tr,\n    X_val_sbert, y_val,\n    X_test_sbert, y_test,\n    label_encoder.classes_,\n    run_name=\"SBERT\"\n)\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-01-28T13:49:48.614806Z",
     "iopub.execute_input": "2026-01-28T13:49:48.615106Z",
     "iopub.status.idle": "2026-01-28T13:54:36.946566Z",
     "shell.execute_reply.started": "2026-01-28T13:49:48.61508Z",
     "shell.execute_reply": "2026-01-28T13:54:36.9459Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "model_lgb_bge, val_pred_lgb_bge, test_pred_lgb_bge = run_lgbm_multiclass(\n    X_tr_bge, y_tr,\n    X_val_bge, y_val,\n    X_test_bge, y_test,\n    label_encoder.classes_,\n    run_name=\"BGE-M3\"\n)\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-01-28T13:54:36.947931Z",
     "iopub.execute_input": "2026-01-28T13:54:36.948163Z",
     "iopub.status.idle": "2026-01-28T14:02:28.040435Z",
     "shell.execute_reply.started": "2026-01-28T13:54:36.948141Z",
     "shell.execute_reply": "2026-01-28T14:02:28.039493Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "def run_linear_svm(X_tr_emb, y_tr, X_val_emb, y_val, X_test_emb, y_test, class_names, run_name):\n    # LinearSVC marche bien en haute dimension (embeddings), très bon baseline\n    clf = LinearSVC(class_weight=\"balanced\", random_state=42)\n    clf.fit(X_tr_emb, y_tr)\n\n    val_pred = clf.predict(X_val_emb)\n    test_pred = clf.predict(X_test_emb)\n\n    print(f\"{run_name} - validation\")\n    print(classification_report(y_val, val_pred, target_names=class_names))\n\n    print(f\"{run_name} - test\")\n    print(classification_report(y_test, test_pred, target_names=class_names))\n\n    add_result(\"LinearSVM\", run_name, \"validation\", y_val, val_pred)\n    add_result(\"LinearSVM\", run_name, \"test\", y_test, test_pred)\n\n    return clf, val_pred, test_pred\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-01-28T14:02:28.041995Z",
     "iopub.execute_input": "2026-01-28T14:02:28.042261Z",
     "iopub.status.idle": "2026-01-28T14:02:28.048702Z",
     "shell.execute_reply.started": "2026-01-28T14:02:28.042235Z",
     "shell.execute_reply": "2026-01-28T14:02:28.047931Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "clf_svm_sbert, val_pred_svm_sbert, test_pred_svm_sbert = run_linear_svm(\n    X_tr_sbert, y_tr,\n    X_val_sbert, y_val,\n    X_test_sbert, y_test,\n    label_encoder.classes_,\n    run_name=\"SBERT\"\n)\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-01-28T14:02:28.049452Z",
     "iopub.execute_input": "2026-01-28T14:02:28.049759Z",
     "iopub.status.idle": "2026-01-28T14:03:07.151343Z",
     "shell.execute_reply.started": "2026-01-28T14:02:28.049734Z",
     "shell.execute_reply": "2026-01-28T14:03:07.150575Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "clf_svm_bge, val_pred_svm_bge, test_pred_svm_bge = run_linear_svm(\n    X_tr_bge, y_tr,\n    X_val_bge, y_val,\n    X_test_bge, y_test,\n    label_encoder.classes_,\n    run_name=\"BGE-M3\"\n)\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-01-28T14:03:07.152855Z",
     "iopub.execute_input": "2026-01-28T14:03:07.153141Z",
     "iopub.status.idle": "2026-01-28T14:03:52.264808Z",
     "shell.execute_reply.started": "2026-01-28T14:03:07.153085Z",
     "shell.execute_reply": "2026-01-28T14:03:52.264056Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "df_results = pd.DataFrame(RESULTS).sort_values([\"embeddings\", \"modele\", \"split\"])\ndf_results\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-01-28T14:03:52.266154Z",
     "iopub.execute_input": "2026-01-28T14:03:52.26667Z",
     "iopub.status.idle": "2026-01-28T14:03:52.284331Z",
     "shell.execute_reply.started": "2026-01-28T14:03:52.266633Z",
     "shell.execute_reply": "2026-01-28T14:03:52.283711Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "out_csv = \"/kaggle/working/results_embeddings_classifiers.csv\"\ndf_results.to_csv(out_csv, index=False)\nout_csv\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-01-28T14:03:52.285664Z",
     "iopub.execute_input": "2026-01-28T14:03:52.285935Z",
     "iopub.status.idle": "2026-01-28T14:03:52.293948Z",
     "shell.execute_reply.started": "2026-01-28T14:03:52.285905Z",
     "shell.execute_reply": "2026-01-28T14:03:52.292772Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "from sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import classification_report\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-01-28T14:03:52.295506Z",
     "iopub.execute_input": "2026-01-28T14:03:52.295777Z",
     "iopub.status.idle": "2026-01-28T14:03:52.329673Z",
     "shell.execute_reply.started": "2026-01-28T14:03:52.295749Z",
     "shell.execute_reply": "2026-01-28T14:03:52.329032Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "def run_mlp(X_tr_emb, y_tr, X_val_emb, y_val, X_test_emb, y_test, class_names, run_name):\n    # MLP non linéaire avec early stopping sur un split interne du train\n    # On garde ton vrai X_val pour l'évaluation comparable aux autres modèles\n    clf = MLPClassifier(\n        hidden_layer_sizes=(256, 128),\n        activation=\"relu\",\n        solver=\"adam\",\n        alpha=1e-4,\n        batch_size=256,\n        learning_rate_init=1e-3,\n        max_iter=200,\n        early_stopping=True,\n        validation_fraction=0.1,\n        n_iter_no_change=10,\n        random_state=42\n    )\n\n    clf.fit(X_tr_emb, y_tr)\n\n    val_pred = clf.predict(X_val_emb)\n    test_pred = clf.predict(X_test_emb)\n\n    print(f\"{run_name} - validation\")\n    print(classification_report(y_val, val_pred, target_names=class_names))\n\n    print(f\"{run_name} - test\")\n    print(classification_report(y_test, test_pred, target_names=class_names))\n\n    add_result(\"MLP\", run_name, \"validation\", y_val, val_pred)\n    add_result(\"MLP\", run_name, \"test\", y_test, test_pred)\n\n    return clf, val_pred, test_pred\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-01-28T14:03:52.331886Z",
     "iopub.execute_input": "2026-01-28T14:03:52.332345Z",
     "iopub.status.idle": "2026-01-28T14:03:52.340487Z",
     "shell.execute_reply.started": "2026-01-28T14:03:52.332313Z",
     "shell.execute_reply": "2026-01-28T14:03:52.339871Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "clf_mlp_sbert, val_pred_mlp_sbert, test_pred_mlp_sbert = run_mlp(\n    X_tr_sbert, y_tr,\n    X_val_sbert, y_val,\n    X_test_sbert, y_test,\n    label_encoder.classes_,\n    run_name=\"SBERT\"\n)\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-01-28T14:03:52.342713Z",
     "iopub.execute_input": "2026-01-28T14:03:52.342965Z",
     "iopub.status.idle": "2026-01-28T14:04:05.572826Z",
     "shell.execute_reply.started": "2026-01-28T14:03:52.342937Z",
     "shell.execute_reply": "2026-01-28T14:04:05.571988Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "clf_mlp_bge, val_pred_mlp_bge, test_pred_mlp_bge = run_mlp(\n    X_tr_bge, y_tr,\n    X_val_bge, y_val,\n    X_test_bge, y_test,\n    label_encoder.classes_,\n    run_name=\"BGE-M3\"\n)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-01-28T14:04:05.575241Z",
     "iopub.execute_input": "2026-01-28T14:04:05.577601Z",
     "iopub.status.idle": "2026-01-28T14:04:40.504725Z",
     "shell.execute_reply.started": "2026-01-28T14:04:05.577568Z",
     "shell.execute_reply": "2026-01-28T14:04:40.503398Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "df_results = pd.DataFrame(RESULTS).sort_values([\"embeddings\", \"modele\", \"split\"])\ndf_results\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-01-28T14:04:40.506569Z",
     "iopub.execute_input": "2026-01-28T14:04:40.506891Z",
     "iopub.status.idle": "2026-01-28T14:04:40.524286Z",
     "shell.execute_reply.started": "2026-01-28T14:04:40.506861Z",
     "shell.execute_reply": "2026-01-28T14:04:40.523694Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "import pandas as pd\n\n# Chemin du fichier exporté précédemment\nresults_path = \"/kaggle/working/results_embeddings_classifiers.csv\"\n\ndf_results = pd.read_csv(results_path)\n\nprint(df_results.head())\nprint(df_results.shape)\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-01-28T14:04:40.526709Z",
     "iopub.execute_input": "2026-01-28T14:04:40.527005Z",
     "iopub.status.idle": "2026-01-28T14:04:40.540441Z",
     "shell.execute_reply.started": "2026-01-28T14:04:40.526978Z",
     "shell.execute_reply": "2026-01-28T14:04:40.539853Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "import pandas as pd\n\n# DataFrame brut\n#df_results = pd.DataFrame(RESULTS)\n\n# On garde uniquement le split test\ndf_test = df_results[df_results[\"split\"] == \"test\"].copy()\n\n# Suppression des doublons éventuels (sécurité)\ndf_test = df_test.drop_duplicates(subset=[\"embeddings\", \"modele\"])\n\n# Tri par accuracy puis f1_weighted (du meilleur au moins bon)\ndf_test = df_test.sort_values(\n    by=[\"accuracy\", \"f1_weighted\"],\n    ascending=False\n).reset_index(drop=True)\n\ndf_test\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-01-28T14:04:40.541742Z",
     "iopub.execute_input": "2026-01-28T14:04:40.542Z",
     "iopub.status.idle": "2026-01-28T14:04:40.567553Z",
     "shell.execute_reply.started": "2026-01-28T14:04:40.541972Z",
     "shell.execute_reply": "2026-01-28T14:04:40.566964Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Sauvegarde classificateurs\n",
    "joblib.dump(clf_sbert, os.path.join(OUTPUT_DIR, 'clf_lr_sbert.joblib'))\n",
    "joblib.dump(clf_bge, os.path.join(OUTPUT_DIR, 'clf_lr_bge.joblib'))\n",
    "\n",
    "# Sauvegarde des modeles LightGBM\n",
    "try:\n",
    "    model_lgb_sbert.save_model(os.path.join(OUTPUT_DIR, 'clf_lgb_sbert.txt'))\n",
    "except Exception as e:\n",
    "    print('LightGBM SBERT not saved:', e)\n",
    "\n",
    "try:\n",
    "    model_lgb_bge.save_model(os.path.join(OUTPUT_DIR, 'clf_lgb_bge.txt'))\n",
    "except Exception as e:\n",
    "    print('LightGBM BGE not saved:', e)\n",
    "\n",
    "# Sauvegarde des autres modeles\n",
    "try:\n",
    "    joblib.dump(clf_svm_sbert, os.path.join(OUTPUT_DIR, 'clf_svm_sbert.joblib'))\n",
    "except Exception as e:\n",
    "    print('SVM SBERT not saved:', e)\n",
    "\n",
    "try:\n",
    "    joblib.dump(clf_svm_bge, os.path.join(OUTPUT_DIR, 'clf_svm_bge.joblib'))\n",
    "except Exception as e:\n",
    "    print('SVM BGE not saved:', e)\n",
    "\n",
    "try:\n",
    "    joblib.dump(clf_mlp_sbert, os.path.join(OUTPUT_DIR, 'clf_mlp_sbert.joblib'))\n",
    "except Exception as e:\n",
    "    print('MLP SBERT not saved:', e)\n",
    "\n",
    "try:\n",
    "    joblib.dump(clf_mlp_bge, os.path.join(OUTPUT_DIR, 'clf_mlp_bge.joblib'))\n",
    "except Exception as e:\n",
    "    print('MLP BGE not saved:', e)\n",
    "\n",
    "# Sauvegarde predictions\n",
    "np.save(os.path.join(OUTPUT_DIR, 'val_pred_sbert.npy'), val_pred_sbert)\n",
    "np.save(os.path.join(OUTPUT_DIR, 'test_pred_sbert.npy'), test_pred_sbert)\n",
    "\n",
    "# Sauvegarde resultats\n",
    "df_results.to_csv(os.path.join(OUTPUT_DIR, 'results_embeddings_classifiers.csv'), index=False)\n",
    "\n",
    "# Sauvegarde encoder\n",
    "joblib.dump(label_encoder, os.path.join(OUTPUT_DIR, 'label_encoder.joblib'))\n",
    "\n",
    "# Sauvegarde du meilleur modele\n",
    "try:\n",
    "    df_test = df_results[df_results['split'] == 'test'].drop_duplicates(subset=['embeddings', 'modele'])\n",
    "    df_test = df_test.sort_values(by=['accuracy', 'f1_weighted'], ascending=False).reset_index(drop=True)\n",
    "    best = df_test.iloc[0].to_dict()\n",
    "    model_files = {\n",
    "        ('LightGBM', 'SBERT'): ('clf_lgb_sbert.txt', 'lightgbm'),\n",
    "        ('LightGBM', 'BGE-M3'): ('clf_lgb_bge.txt', 'lightgbm'),\n",
    "        ('LogisticRegression', 'SBERT'): ('clf_lr_sbert.joblib', 'sklearn'),\n",
    "        ('LogisticRegression', 'BGE-M3'): ('clf_lr_bge.joblib', 'sklearn'),\n",
    "        ('LinearSVM', 'SBERT'): ('clf_svm_sbert.joblib', 'sklearn'),\n",
    "        ('LinearSVM', 'BGE-M3'): ('clf_svm_bge.joblib', 'sklearn'),\n",
    "        ('MLP', 'SBERT'): ('clf_mlp_sbert.joblib', 'sklearn'),\n",
    "        ('MLP', 'BGE-M3'): ('clf_mlp_bge.joblib', 'sklearn'),\n",
    "    }\n",
    "    key = (best.get('modele'), best.get('embeddings'))\n",
    "    filename, model_type = model_files.get(key, (None, None))\n",
    "    if filename is None:\n",
    "        print('Best model not saved: unknown key', key)\n",
    "    else:\n",
    "        embedding_model_name = None\n",
    "        if best.get('embeddings') == 'SBERT':\n",
    "            embedding_model_name = sbert_name\n",
    "        elif best.get('embeddings') == 'BGE-M3':\n",
    "            embedding_model_name = bge_name\n",
    "        meta = {\n",
    "            'modele': best.get('modele'),\n",
    "            'embeddings': best.get('embeddings'),\n",
    "            'model_filename': filename,\n",
    "            'model_type': model_type,\n",
    "            'embedding_model_name': embedding_model_name,\n",
    "        }\n",
    "        with open(os.path.join(OUTPUT_DIR, 'best_model_meta.json'), 'w', encoding='utf-8') as f:\n",
    "            json.dump(meta, f, ensure_ascii=False, indent=2)\n",
    "        print('Best model meta saved:', meta)\n",
    "except Exception as e:\n",
    "    print('Best model not saved:', e)\n",
    "\n",
    "print('Sauvegarde terminee -> Save Version')\n"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-01-28T14:18:20.568305Z",
     "iopub.execute_input": "2026-01-28T14:18:20.568634Z",
     "iopub.status.idle": "2026-01-28T14:18:20.579019Z",
     "shell.execute_reply.started": "2026-01-28T14:18:20.568594Z",
     "shell.execute_reply": "2026-01-28T14:18:20.578404Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  }
 ]
}